# **Driver Coupon Analysis**

This repository analyzes a UCI survey dataset to understand which drivers are likely to accept time-limited coupons (restaurant, coffee house, bar, take-away, etc.). The project applies exploratory data analysis, visualization, and simple probabilistic modeling to identify factors that correlate with coupon acceptance.

**High-Level Summary of Findings**

- Dataset & Cleaning: Original dataset 12,684 rows × 26 cols. Removed 74 duplicate rows, dropped the car column (99% missing), and dropped remaining rows with NaNs. Cleaned data saved to coupons_cleaned.csv (final ~12,007 rows × 25 cols).

- Overall Acceptance: 56.8% of observations accepted a coupon (≈6,825/12,007) vs 43.2% who did not — an acceptance lead of ~13.6%

- Coupon Distribution: Coupon types are unevenly distributed (e.g., Coffee House and Restaurant(<20) are common). Raw-count analyses can be biased by these frequencies and should account for per-type prevalence.

- Temperature / Weather: Temperature is tri-modal (≈30°F, 55°F, 80°F) and shows no clear visual relationship with coupon acceptance — temperature is not a strong driver.
    
- Bar Coupon Acceptance Analysis

    - Bar coupons are less likely to be accepted overall (≈41.2% acceptance for bar coupons; 785 accepted vs 1,121 not accepted, total 1,906).
      
    - Frequency matters: drivers who visit bars >3/month accept bar coupons at ~76.2% vs ~37.2% for ≤3/month — a very large effect.
      
    - Demographics amplify effect: drivers who visit bars ≥1/month and are >25 years old accept at ~69.0% vs ~33.7% for others.
      
    - Drivers who visit bars ≥1/month, travel without kids, and are non-farming occupations have much higher acceptance — useful targeting signal.
    
- Coffee House Coupon Acceptance Analysis

    - Overall nearly even acceptance / rejection.
      
    - Acceptance increases with historical Coffee House visit frequency (positive frequency effect).
 
    - Passenger type matters: Alone and Partner show higher acceptance; Kid(s) shows the lowest.
 
    - Route/convenience matters: acceptance is higher when the coupon venue is on the same direction/route as the trip.
 
    - Destination also shifts acceptance (discretionary/no-urgent trips show higher acceptance).
    
Final Product depicting the findings that highlights the differences between customers who did and did not accept the coupons in available here: [Final Report](docs/final_analysis_report.md)

Notebook
- The full analysis is in the Jupyter notebook: `prompt.ipynb` (root). 

Quick start
1. Create a virtual environment (recommended):

```bash
# ucbmlai-a51-driver-coupon-analysis

This repository contains an exploratory analysis of a survey-style dataset used to study drivers' likelihood of accepting time-limited coupons (restaurant, coffee house, bar, take-away, etc.). The project focuses on data cleaning, exploratory data analysis (EDA), visualizations, and straightforward subgroup analyses to surface factors correlated with coupon acceptance.

**Quick Links**
- **Assignment instructions:** `assignment_instructions.md`
- **Data dictionary:** `coupons_data_dictionary.md`
- **Notebook:** `prompt.ipynb` (root)

**Quick Start**
- **Create a virtual environment:**

```bash
python -m venv .venv
source .venv/bin/activate
```

- **Install required packages (minimal):**

```bash
python -m pip install pandas numpy matplotlib seaborn jupyterlab
```

- **Run the dataset summary script:**

```bash
python src/describe_columns.py --csv data/raw/coupons.csv --max-values 10
```

- **Open the analysis notebook:**

```bash
jupyter lab prompt.ipynb
```

**Data files**
- **Raw:** `data/raw/coupons.csv`
- **Processed / cleaned (generated by notebook):** `data/processed/coupons_cleaned.csv` (may be regenerated by the notebook)

**What’s included**
- **`prompt.ipynb`**: analysis notebook containing data loading, cleaning steps (deduplication, dropping `car` column, dropping rows with remaining NaNs), EDA plots, and findings. Note: earlier versions contained VS Code cell wrappers; if you experience rendering issues, open the notebook in JupyterLab and re-save it to standardize the format.
- **`src/describe_columns.py`**: small helper script that prints per-column unique counts, missing counts, and top value frequencies for a CSV file.
- **`assignment_instructions.md`**: extracted assignment instructions and tasks.
- **`coupons_data_dictionary.md`**: data dictionary describing each column in `coupons.csv`.
- **`images/`**: exported figures generated by the notebook.

**Usage notes & recommendations**
- **Relative links:** The notebook and markdown files use relative links (e.g., `assignment_instructions.md`) so previews in VS Code and GitHub will open targets correctly. If you move files into `docs/` or another folder, update links accordingly.
- **Reproducibility:** Add a `requirements.txt` (e.g., `pip freeze > requirements.txt`) or an `environment.yml` to pin dependency versions for reproducible runs.
- **Notebook portability:** If your `prompt.ipynb` includes VS Code-wrapped cells, open and re-save it in JupyterLab to produce a standard `.ipynb` compatible with Binder and other viewers.

**Suggested next steps**
- Move notebooks to `notebooks/` and processed data to `data/processed/` for clearer separation of raw/derived artifacts.
- Add `requirements.txt` and a short `CONTRIBUTING.md` with commands to reproduce the cleaned dataset and regenerate figures.

If you want, I can also (a) convert and save `prompt.ipynb` to a standard Jupyter format in `notebooks/`, (b) create a `requirements.txt`, and (c) move the processed data into `data/processed/`. Tell me which of these you want me to do next.
